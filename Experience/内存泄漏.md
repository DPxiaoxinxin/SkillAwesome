# 内存泄漏

## 现象

刚接手不久的项目，有一个内存泄漏的问题，以下是涉及到的相关信息：

* 项目概述：给客户端管理容器功能以搭建游戏私服
* 技术框架：Python+Flask+内部自研的Restful框架+Kubernetes，Docker容器化部署
* 环境：10台16核32G机器，管理大约400台20核256G的K8s节点
* 访问量：约4000w级/日
* 内存泄漏现象：
  * 10台机器上线后内存占用快速增60%到20G左右，然后相对缓慢上涨直到100%；总共17个进程，平均每个占用2G，最高接近4G
  * 前期排查不出原因，扛不住升级为10台20核128G机器，内存占用也能快速攀升至70G左右，然后缓慢上涨。
  * 通过负载均衡器把后端节点摘除屏蔽新请求，内存没有下降

## 背景知识

### Python内存区域

![](https://images2017.cnblogs.com/blog/1089769/201709/1089769-20170919090908056-1998847597.png)

#### 第3层：基础类型对象特有的分配器

* 包含int、dict、list等python基础类型
* 更高抽象层次的内存管理策略, 主要是各类特定对象的缓冲池机制(Python实现并维护)

#### 第2层：python对象分配器

* 实现了创建/销毁Python对象的接口(PyObject_New/Del), 涉及对象参数/引用计数等(Python实现并维护)

* 负责管理pool内部的block
* block大小是8的整数倍，最小满足分配需求，会有个内存对齐，比如申请14字节，给你16字节
* block三种状态：已经分配，使用完毕，未使用

#### 第1层：python低级内存分配器

* 包装了第0层的内存管理接口, 提供统一的raw memory管理接口(Python实现并维护)
  * 封装的原因: 不同操作系统 C 行为不一定一致, 保证可移植性, 相同语义相同行为

* 第1层负责小于等于256K字节的短命对象，有Python的接口函数PyMem_Malloc函数实现
* 三个级别的内存结构：`arena > pool > block`
* arena大小固定为256K
* pool大小固定4K（与操作系统虚拟内存页大小一致）
* 生成和管理arena和pool

#### 第0层：底层通用分配器

* 使用Linux glibc提供的malloc()，free()等管理内存
* 申请的内存大于256K字节，会忠实调用第0层malloc;否则，转给第1层和第2层
* 操作系统提供的内存管理接口, 由操作系统实现并管理, Python不能干涉这一层的行为

#### 第-1层：操作系统虚拟的内存管理器

#### 第-2层：物理内存

### Python垃圾回收

#### 机制

##### 引用计数(主要)

* 每个对象维护一个`ob_ref`字段，用来记录该对象当前被引用的次数，每当新的引用指向该对象时，它的引用计数`ob_ref`加`1`，每当该对象的引用失效时计数`ob_ref`减`1`，一旦对象的引用计数为`0`，该对象立即被回收，对象占用的内存空间将被释放。
* 它的缺点是需要额外的空间维护引用计数，这个问题是其次的，不过最主要的问题是它不能解决对象的“循环引用”，因此，也有很多语言比如Java并没有采用该算法做来垃圾的收集机制。

##### 可达性分析+标记清除

* 标记清除（Mark—Sweep）』算法是一种基于追踪回收（tracing GC）技术实现的垃圾回收算法
  * 第一阶段是标记阶段，GC会把所有的『活动对象』打上标记
    * 对象之间通过引用（指针）连在一起，构成一个有向图，对象构成这个有向图的节点，而引用关系构成这个有向图的边。从根对象（root object）出发，沿着有向边遍历对象，可达的（reachable）对象标记为活动对象，不可达的对象就是要被清除的非活动对象。根对象就是全局变量、调用栈、寄存器。
  * 第二阶段是把那些没有标记的对象『非活动对象』进行回收

* 解决循环引用
* 处理的是一些容器对象，比如list、dict、tuple，instance等，因为对于字符串、数值对象是不可能造成循环引用问题。Python使用一个双向链表将这些容器对象组织起来
* 这种简单粗暴的标记清除算法也有明显的缺点：清除非活动的对象前它必须顺序扫描整个堆内存，哪怕只剩下小部分活动对象也要扫描所有对象。
* **但是python3.4以前，对象内定义了`__del__`方法的循环引用，无法被回收**

##### 分代回收

- 分代回收是一种以空间换时间的操作方式，Python将内存根据对象的存活时间划分为不同的集合，每个集合称为一个代，Python将内存分为了3“代”，分别为年轻代（第0代）、中年代（第1代）、老年代（第2代），他们对应的是3个链表，它们的垃圾收集频率与对象的存活时间的增大而减小。
- 新创建的对象都会分配在**年轻代**，年轻代链表的总数达到上限时，Python垃圾收集机制就会被触发，把那些可以被回收的对象回收掉，而那些不会回收的对象就会被移到**中年代**去，依此类推，**老年代**中的对象是存活时间最久的对象，甚至是存活于整个系统的生命周期内。
- 同时，分代回收是建立在标记清除技术基础之上。分代回收同样作为Python的辅助垃圾收集技术处理那些容器对象

#### 触发垃圾回收条件

1. 调用`gc.collect()`,需要先导入`gc`模块。
2. 当`gc`模块的计数器达到阀值的时候。
3. 程序退出的时候。

### Linux内存分配

#### 内存分配方式

**这两种方式分配的都是虚拟内存，没有分配物理内存**。**在第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系。**

##### brk：

* 小于128K的内存

* **将数据段(.data)的最高地址指针_edata往高地址推；*
* 中间对象被回收后，如果最高地址的对象没被回收，中间对象的内存地址不会被回收，可以复用。直到最高地址的对象被回收后，把_edata指针逐渐拉下来，才回收中间对象

##### mmap：

* **较大的对象在进程的虚拟地址空间中（堆和栈中间，称为文件映射区域的地方）找一块空闲的虚拟内存**。
* 内存可直接被回收

## 内存泄漏排查思路

### 基础资源

#### 基础资源不足

* 折算下来500QPS，另外项目主要是IO操作，资源充足。
* 后期尝试过加机器资源，也证明不是资源不足问题。

### 代码层

#### 使用了大对象

* Review了代码，很少有使用大对象的地方。
  * 有一处拉取数据进行本地缓存，频率为30min，拉取的字符串大概有90m，但处理后缓存的数据很小。
* 使用pyrasite-shell工具attach了进程，用guppy查看对象占用情况，对象数量和总大小没发现异常。

#### 对象无法被回收

* Review代码，未发现有特殊循环引用的地方。不排除是第三方库或框架导致，用objgraph查看对象引用链，也无发现异常。

#### 没有进行垃圾回收

* 使用pyrasite-shell工具attach了进程，用gc.collect()强制回收，用guppy对比前后对象占用情况，没发现异常。

### Web层

#### 开启了特殊模式如DEBUG

* 发现线上开启了debug模式，官方文档提示可能会导致内存增加。关闭后内存未下降。

#### 使用了本地缓存

* Review代码，发现一处使用本地缓存，因开了cpu核数+1共17个进程，每个进程都有一处本地缓存。但估摸影响不大。将该本地缓存迁移至redis，内存占用未下降，证实不是该原因。

### 系统层

##### Linux内存分配管理机制问题

可能是由于高并发导致内存碎片，尝试把glibc换成google开源的tcmalloc，经验证无效。

##### Docker问题

更换系统镜像，经验证可解决。内存稳定在20G，单个进程占用600m左右。



## 参考文章

[[春节红包系列]一次"内存泄漏"引发的血案](https://cloud.tencent.com/developer/article/1138651)

[linux环境内存分配原理 mallocinfo](https://www.cnblogs.com/dongzhiquan/p/5621906.html)

[python 内存问题（glibc库的malloc相关）](https://www.cnblogs.com/GO-NO-1/p/8822258.html)

[为什么linux下多线程程序如此消耗虚拟内存](http://blog.jobbole.com/83878/)

[浅析Linux堆溢出之fastbin](https://www.freebuf.com/news/88660.html)

[十问 Linux 虚拟内存管理 ( 二 )](https://cloud.tencent.com/developer/article/1004429)

[Lnux的虚拟内存管理有几个关键概念](https://bingoex.github.io/2017/01/01/linux-memory-3/)