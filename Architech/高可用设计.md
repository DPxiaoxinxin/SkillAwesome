# 稳定性&高可用设计

[TOC]

## 参考文章

[《关于高可用的系统》](https://coolshell.cn/articles/17459.html)

## 理解高可用系统

### **让系统做到full-time的可用性(细节之处全是魔鬼)**

#### 对软硬件的冗余，以消除单点故障。

任何系统都会有一个或多个冗余系统做standby

* 冗余结点最大的难题就是对于有状态的结点的数据复制和数据一致性的保证（无状态结点的冗余相对比较简单）

#### 对故障的检测和恢复

检测故障以及用备份的结点接管故障点。这也就是failover

#### 需要很可靠的交汇点（CrossOver）

这是一些不容易冗余的结点，比如域名解析，负载均衡器等。

### 冗余数据所带来的一致性问题是魔鬼中的魔鬼

* 如果系统的数据镜像到冗余结点是异步的，那么在failover的时候就会出现数据差异的情况。
* 如果系统在数据镜像到冗余结点是同步的，那么就会导致冗余结点越多性能越慢。
* 所以，很多高可用系统都是在做各种取舍，这需要比对着业务的特点来的
  * 比如银行账号的余额是一个状态型的数据，那么，冗余时就必需做到强一致性
  * 订单记录属于追加性的数据，那么在failover的时候，就可以到备机上进行追加，这样就比较简单了（阿里目前所谓的异地双活其实根本做不到状态型数据的双活）。

## 高可用的设计原理

### 要做到数据不丢，就必需要持久化

### 要做到服务高可用，就必需要有备用（复本），无论是应用结点还是数据结点

### 要做到复制，就会有数据一致性的问题。

### 我们不可能做到100%的高可用，也就是说，我们能做到几个9个的SLA。

### 高可用系统的解决方案

![](https://coolshell.cn/wp-content/uploads/2014/01/Transaction-Across-DataCenter.jpg)

这个图来自来自：Google App Engine的co-founder Ryan Barrett在2009年的Google I/O上的演讲《[Transaction Across DataCenter](http://snarfed.org/transactions_across_datacenters_io.html)》（视频： <http://www.youtube.com/watch?v=srOgpXECblk>）

#### 常见方案

参考《[分布式系统的事务处理](https://coolshell.cn/articles/10910.html)》

##### 冷备

* 做定时全量、增量的备份，在系统一致性、可用性出现问题时，能够通过备份数据还原系统到达某一点。
* 操作难度小，但存在即时性低、丢失率高的问题。

##### Master-Slave

* Slave一般是Master的备份
  * 读写请求都由Master负责。
  * 写请求写到Master上后，由Master同步到Slave上。
    * 可以使用异步，也可以使用同步，可以使用Master来push，也可以使用Slave来pull。
    * 通常来说是Slave来周期性的pull

##### Master-Master

* 一个系统存在两个或多个Master，每个Master都提供read-write服务
* 是Master-Slave的加强版，数据间同步一般是通过Master间的异步完成，所以是最终一致性
* 好处是，一台Master挂了，别的Master可以正常做读写服务，他和Master-Slave一样，当数据没有被复制到别的Master上时，数据会丢失。很多数据库都支持Master-Master的Replication的机制。

##### Two/Three Phase Commit(2PC)

* 在分布式系统中，每个节点虽然可以知晓自己的操作时成功或者失败，却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为**协调者**的组件来统一掌控所有节点(称作**参与者**)的操作结果并最终指示这些节点是否要把操作结果进行真正的提交(比如将更新后的数据写入磁盘等等)。

##### Paxos

* 解决的问题是在一个可能发生上述异常的分布式系统中如何就某个值达成一致，保证不论发生以上任何异常，都不会破坏决议的一致性。
* 一个典型的场景是，在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点都执行相同的操作序列，那么他们最后能得到一个一致的状态。为保证每个节点执行相同的命令序列，需要在每一条指令上执行一个「一致性算法」以保证每个节点看到的指令一致

#### 各个高可用方案的问题(软件层面)

另外，现今开源软件中，很多缓存，消息中间件或数据库都有持久化和Replication的设计，从而也都有高可用解决方案，但是开源软件一般都没有比较高的SLA，所以，如果我们使用开源软件的话，需要注意这一点。

- 对于最终一致性来说，在宕机的情况下，会出现数据没有完全同步完成，会出现数据差异性。
- 对于强一致性来说，要么使用性能比较慢的[XA系](https://en.wikipedia.org/wiki/X/Open_XA)的两阶段提交的方案，要么使用性能比较好，但是实现比较复杂的Paxos协议。

### 高可用性SAL的定义

* 全称[Service Level Agrement](https://en.wikipedia.org/wiki/Service-level_agreement)，**测量系统的高可用性**，也就是有几个9的高可用性，即故障发生到恢复的时间。
* **这不仅仅只是一个技术指标，而是一种服务提供商和用户之间的contract或契约**。**这种工业级的玩法，就像飞机一样，并不是把飞机造出来就好了，还有大量的无比专业的配套设施、工具、流程、管理和运营**。

| 系统可用性%    | 宕机时间/年 | 宕机时间/月 | 宕机时间/周 | 宕机时间/天 |
| -------------- | ----------- | ----------- | ----------- | ----------- |
| 90% (1个9)     | 36.5 天     | 72 小时     | 16.8 小时   | 2.4 小时    |
| 99% (2个9)     | 3.65 天     | 7.20 小时   | 1.68 小时   | 14.4 分     |
| 99.9% (3个9)   | 8.76 小时   | 43.8 分     | 10.1 分钟   | 1.44 分     |
| 99.99% (4个9)  | 52.56 分    | 4.38 分     | 1.01 分钟   | 8.66 秒     |
| 99.999% (5个9) | 5.26 分     | 25.9 秒     | 6.05 秒     | 0.87 秒     |

### 影响高可用的因素

#### 无计划的宕机原因

下图来自Oracle的 《[High Availability Concepts and Best Practices](https://docs.oracle.com/cd/A91202_01/901_doc/rac.901/a89867/pshavdtl.htm)》

 

##### ![unplaned_downtime](https://coolshell.cn/wp-content/uploads/2016/08/unplaned_downtime.gif)

#### 有计划的宕机原因

下图来自Oracle的 《[High Availability Concepts and Best Practices](https://docs.oracle.com/cd/A91202_01/901_doc/rac.901/a89867/pshavdtl.htm)》

![planned_downtime](https://coolshell.cn/wp-content/uploads/2016/08/planned_downtime.gif)

#### 宕机原因总结

##### 无计划的

- 系统级的故障 –  包括主机、操作系统、中间件、数据库、网络、电源以及外围设备
- 数据和中介的故障 – 包括人员误操作、硬盘故障、数据乱了
- 还有：自然灾害、人为破坏、以及供电问题。

##### 有计划的

- 日常任务：备份，容量规划，用户和安全管理，后台批处理应用
- 运维相关：数据库维护、应用维护、中间件维护、操作系统维护、网络维护
- 升级相关：数据库、应用、中间件、操作系统、网络、包括硬件升级

### 真正决定高可用系统的本质原因

**如果你没有一套科学的牛逼的软件工程的管理，没有牛逼先进的自动化的运维工具，没有技术能力很牛逼的工程师团队，怎么可能出现高可用的系统啊**。

##### **一套严谨科学的工程管理**，其中包括但不限于了：

###### 软件的设计、编码、测试、上线和软件配置管理的水平

###### 工程师的人员技能水平

###### 运维的管理和技术水平

###### 数据中心的运营管理水平

###### 依赖于第三方服务的管理水平

###### 深层交的东西则是——对工程这门科学的尊重：

- 对待技术的态度
- 一个公司的工程文化
- 领导者对工程的尊重

## 搭建高可用系统的一些解决方案

### 高可用方法论

| 问题           | 典型案例                   | 增大 MTBF                                        | 减小 MTTR                              |
| -------------- | -------------------------- | ------------------------------------------------ | -------------------------------------- |
| 程序、配置 Bug | 程序、配置 Bug             | 提升研发、测试质量，灰度发布                     | 监控告警、快速回滚                     |
| 机器、机房故障 | 宕机、机房断电             | 硬件冗余、多机房                                 | 自动故障转移，切流到其他冗余机器、机房 |
| 突发流量       | 上游系统异常重试、外部攻击 | 上游系统容错调度防雪崩、流量配额、防攻击、防抓取 | 其他同容量不足                         |
| 容量不足       | 主流程容量不足             | 容量规划、容量预警                               | 限流、降级、熔断弱依赖、快速扩容       |
| 依赖服务故障   | 依赖服务失败率高、超时严重 | 弱依赖降级解耦，强依赖递归使用前述方法增强可靠性 | 熔断弱依赖                             |

### 扩展：通过冗余部署，避免单点故障

最常见的提升系统可靠性的方法，系统的扩展可以避免单点故障，即一个节点出现了问题造成整个系统无法正常工作。

#### 垂直扩展

* 是在同一逻辑单元里添加资源从而满足系统处理能力上升的需求
* **能够提升系统处理能力，但不能解决单点故障问题**。
* 优点：扩展简单。
* 缺点：扩展能力有限。

#### 水平扩展(最常见)

* 通过增加一个或多个逻辑单元，并使得它们像整体一样的工作
* **通过冗余部署解决了单点故障，同时又提升了系统处理能力。**
* 优点：扩展能力强。
* 缺点：增加系统复杂度，维护成本高，系统需要是无状态的、可分布式的。
* 场景
  * 通常我们在部署应用服务器的时候，都会部署多台，然后使用 nginx 来做负载均衡，nginx 使用心跳机制来检测服务器的正常与否，无响应的服务就从集群中剔除。这样的集群中每台服务器的角色是相同的，同时提供一样的服务。 
  * 在数据库的部署中，为了防止单点故障，一般会使用一主多从，通常写操作只发生在主库。不同数据库之间角色不同。当主机宕机时，一台从库可以自动切换为主机提供服务。

### 隔离：避免业务之间的相互影响及单点故障

是对系统、业务所占有的资源进行隔离，限制某个业务对资源的占用数量，避免一个业务占用整个系统资源，对其他业务造成影响。

#### 线程池隔离

不同的业务使用不同的线程池，避免低优先级的任务阻塞高优先级的任务。或者高优先级的任务过多，导致低优先级任务永远不会执行。 

#### 进程隔离

Linux 中有用于进程资源隔离的 Linux CGroup，通过物理限制的方式为进程间资源控制提供了简单的实现方式，为 Linux Container 技术、虚拟化技术的发展奠定了技术基础

#### 模块隔离、应用隔离

很多线上故障的发生源于代码修改后，测试不到位导致。按照代码或业务的易变程度来划分模块或应用，把变化较少的划分到一个模块或应用中，变化较多的划分到另一个模块或应用中。减少代码修改影响的范围，也就减少了测试的工作量，减少了故障出现的概率

#### 机房隔离

主要是为了避免单个机房网络问题或断电

#### 数据的读写分离

一方面，将对实时性要求不高的读操作，放到 DB 从库上执行，有利于减轻 DB 主库的压力。另一方面，将一些耗时离线业务 sql 放到 DB 从库上执行，能够减少慢 sql 对 DB 主库的影响，保证线上业务的稳定可靠。

### 解耦：减少依赖及相互间的影响

在软件工程中，对象之间的耦合度就是对象之间的依赖性。对象之间的耦合越高，维护成本越高，因此对象的设计应使模块之间的耦合度尽量小。

假设有两个模块A、B，A依赖B

#### 通过接口交互解耦

模块A和模块B只通过接口交互，只要接口设计不变，那么模块B内部细节的变化不影响模块A对模块B服务能力的消费。 

* 面向接口设计下真正实现了将接口契约的定义和接口的实现彻底分离，实现变化不影响到接口契约，自然不影响到基于接口的交互。
* 模块A和B之间的松耦合，主要通过合理的模块划分、接口设计来完成。如果出现循环依赖，可以将模块A、B共同依赖的部分移除到另一个模块C中，将A、B之间的相互依赖，转换为A、B同时对C的依赖。

#### 同步调用转为异步消息交互解耦

* 比如购买商品涉及多个系统调用，通过消息中间件的加入，进行削峰解耦以及同步转异步

* 异步消息解耦，适合那些信息流单向流动（类似发布-订阅这样的），实时性要求不高的系统。常见的开源消息队列框架有：Kafka、RabbitMQ、RocketMQ。

### 限流：遇到突发流量时，保证系统稳定

一个系统的处理能力是有上限的，当服务请求量超过处理能力，通常会引起排队，造成响应时间迅速提升。如果对服务占用的资源量没有约束，还可能因为系统资源占用过多而宕机。因此，为了保证系统在遭遇突发流量时，能够正常运行，需要为你的服务加上限流。

#### 分类

##### 按照计数范围

###### 单机限流：一般是为了应对突发流量

###### 全局限流：通常是为了给有限资源进行流量配额

##### 按照计数周期

###### QPS

###### 并发连接数

##### 按照阈值设定方式

###### 固定阈值

###### 动态阈值

#### 漏桶算法

* 漏桶算法(Leaky Bucket)是网络世界中流量整形（Traffic Shaping）或速率限制（Rate Limiting）时经常使用的一种算法，它的主要目的是控制数据注入到网络的速率，平滑网络上的突发流量。
*  **漏桶算法可以使用 Redis 队列来实现，生产者发送消息前先检查队列长度是否超过阈值，超过阈值则丢弃消息，否则发送消息到 Redis 队列中；消费者以固定速率从 Redis 队列中取消息。Redis 队列在这里起到了一个缓冲池的作用，起到削峰填谷、流量整形的作用。**

#### 令牌桶算法

* 对于很多应用场景来说，除了要求能够限制数据的平均传输速率外，还要求允许某种程度的突发传输。这时候漏桶算法可能就不合适了，令牌桶算法更为适合
  * 令牌将按照固定的速率被放入令牌桶中。比如每秒放10个。
  * 桶中最多存放b个令牌，当桶满时，新添加的令牌被丢弃或拒绝。
  * 当一个n个字节大小的数据包到达，将从桶中删除n个令牌，接着数据包被发送到网络上。
  * 如果桶中的令牌不足n个，则不会删除令牌，且该数据包将被限流（要么丢弃，要么缓冲区等待）
* 牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。桶里能够存放令牌的最高数量，就是允许的突发传输量。
* 令牌桶可以在运行时控制和调整数据处理的速率，处理某时的突发流量。放令牌的频率增加可以提升整体数据处理的速度，而通过每次获取令牌的个数增加或者放慢令牌的发放速度和降低整体数据处理速度。

#### 滑动窗口计数法

* 计数法是限流算法里最容易理解的一种，该方法统计最近一段时间的请求量，如果超过一定的阈值，就开始限流。在 TCP 网络协议中，也用到了滑动窗口来限制数据传输速率。
* 滑动窗口计数有两个关键的因素：窗口时长、滚动时间间隔。滚动时间间隔一般等于上图中的一个桶 bucket，窗口时长除以滚动时间间隔，就是一个窗口所包含的 bucket 数目。
* 滑动窗口计数算法的实现，可以查看这篇文章：[降级熔断框架 Hystrix 源码解析：滑动窗口统计](http://www.jianshu.com/p/c1b6497889b4)。

#### 动态限流

* 一般情况下的限流，都需要我们手动设定限流阈值，不仅繁琐，而且容易因系统的发布升级而过时。为此，我们考虑根据系统负载来动态决定是否限流，动态计算限流阈值。可以参考的系统负载参数有：Load、CPU、接口响应时间等。

### 降级：牺牲非核心业务，保证核心业务的高可用

* 指牺牲非核心的业务功能，保证核心功能的稳定运行
  * 要实现优雅的业务降级，需要将功能实现拆分到相对独立的不同代码单元，分优先级进行隔离。
  * 在后台通过开关控制，降级部分非主流程的业务功能，减轻系统依赖和性能损耗，从而提升集群的整体吞吐率。
* 降级的重点是：业务之间有优先级之分
* 业务降级通常需要通过开关工作，开关一般做成配置放在专门的配置系统，配置的修改最好能够实时生效
* 降级往往需要兜底方案的配合，比如系统不可用的时候，对用户进行提示，安抚用户。

### 熔断：减少不稳定的外部依赖对核心服务的影响

* 在分布式系统中，如果调用的远程服务或者资源由于某种原因无法使用时，没有这种过载保护，就会导致请求阻塞在服务器上等待从而耗尽服务器资源。很多时候刚开始可能只是系统出现了局部的、小规模的故障，然而由于种种原因，故障影响的范围越来越大，最终导致了全局性的后果。而这种过载保护就是大家俗称的熔断器(Circuit Breaker)。

* 熔断器的基本原理，包含三个状态

  ![](http://upload-images.jianshu.io/upload_images/7687046-7053e02a8e070b22.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

  * 服务正常运行时的 Closed 状态，当服务调用失败量或失败率达到阈值时，熔断器进入 Open 状态 
  * 在 Open 状态，服务调用不会真正去请求外部资源，会快速失败。 
  * 当进入 Open 状态一段时间后，进入 Half-Open状态，需要去尝试调用几次服务，检查故障的服务是否恢复。如果成功则熔断器关闭，如果失败，则再次进入 Open 状态。

### 发布相关

#### 模块级自动化测试：通过完善的测试，减少发布引起的故障

##### 背景

一个项目上线前需要经历严格的测试过程，但是随着业务不断迭代、系统日益复杂，研发工程师、产品经理、测试工程师等都在测试过程中投入了大量精力，而一个个线上故障却表明测试效果并不是那么完美。究其原因，目前的测试工作主要存在两方面问题： 
1. 测试范围难以界定：随着业务逻辑的不断迭代、系统的不断拆分与细化，精确评估项目改动的影响范围变得越来越困难，从而很难梳理出覆盖全面的测试点。 
2. case验证成本过高：验证一个case需要构造测试场景，包括数据的准备和运行环境的准备，当case量较大或者存在一些涉及多个系统模块且触发条件复杂的case时，这一过程也将花费大量的时间。
##### 方案

针对某一模块，收集模块线上的输入、输出、运行时环境等信息，在离线测试环境通过数据mock模块线上场景，回放收集的线上输入，相同的输入比较测试场景与线上收集的输出作为测试结果。

* 通过简化复杂系统中的不变因素（mock），将系统的测试边界收拢到改动模块，将复杂系统的整体测试转化为改动模块的单元测试。
* 主要适用于系统业务回归，对系统内部重构场景尤其适用。

具体如何收集线上数据呢？有两种方法： 

* AOP：面向切面编程，动态地织入代码，对原有代码的侵入性较小。 
* 埋点：很多公司都开发了一下基础组件，可以在这些基础组件中嵌入数据收集的代码。

#### 灰度发布&回滚：速度与安全性作为妥协，能够有效减少发布故障

* 单点和发布是系统高可用最大的敌人。一般在线上出现故障后，第一个要考虑的就是刚刚有没有代码发布、配置发布，如果有的话就先回滚。

  * 线上故障最重要的是快速恢复，如果等你细细看代码找到问题，没准儿半天就过去了

* 为了减少发布引起问题的严重程度，通常会使用灰度发布策略。灰度发布是速度与安全性作为妥协。他是发布众多保险的最后一道，而不是唯一的一道。

  > 做灰度发布，如果是匀速的，说明没有理解灰度发布的意义。一般来说阶段选择上从 1% -> 10% -> 100% 的指数型增长。这个阶段，是根据具体业务不同按维度去细分的。 这里面的重点在于 1% 并不全是随机选择的，而是根据业务特点、数据特点选择的一批有极强的代表性的实例，去做灰度发布的小白鼠。甚至于每次发布的 第一阶段用户(我们叫 Canary/金丝雀)，根据每次发布的特点不同，是人为挑选的。

* **发布之前必须制定详细的回滚步骤，回滚是解决发布引起的故障的最快的方法。**

### 其他

#### 设置超时

请求对外接口的时候，需要设置合理的超时时间，避免外部接口挂掉时，阻塞整个系统。

#### 失败重试

失败重试能够提高成功率，但是也会造成响应时间变慢，服务提供方压力倍增。具体要不要重试要根据具体情况决定：对响应时间有要求吗？接口失败率如何？重试会不会造成雪崩？



## 应用容灾

### 熔断器Hystrix

#### 服务雪崩

* 因 **服务提供者** 的不可用导致 **服务调用者** 的不可用,并将不可用 **逐渐放大** 的过程.

* 三个阶段：
  * 服务提供者不可用
    * 硬件故障：硬件损坏造成的服务器主机宕机, 网络硬件故障造成的服务提供者的不可访问
    * 程序Bug
    * 缓存击穿：一般发生在缓存应用重启, 所有缓存被清空时,以及短时间内大量缓存失效时. 大量的缓存不命中, 使请求直击后端,造成服务提供者超负荷运行,引起服务不可用. 
    * 用户大量请求：在秒杀和大促开始前,如果准备不充分,用户发起大量请求
  * 重试加大流量
    * 用户重试：用户由于忍受不了界面上长时间的等待,而不断刷新页面甚至提交表单.：
    * 代码逻辑重试：服务调用端的会存在大量服务异常后的重试逻辑. 
  * 服务调用者不可用
    * 同步等待造成的资源耗尽：当服务调用者使用 **同步调用** 时, 会产生大量的等待线程占用系统资源. 一旦线程资源被耗尽,服务调用者提供的服务也将处于不可用状态, 于是服务雪崩效应产生了.

#### 服务雪崩的应对策略

##### 流量控制

###### 网关限流

* 因为Nginx的高性能, 目前一线互联网公司大量采用Nginx+Lua的网关进行流量控制, 由此而来的OpenResty也越来越热门

###### 用户交互限流

* 采用加载动画,提高用户的忍耐等待时间. 
* 提交按钮添加强制等待时间机制.

###### 关闭重试

##### 改进缓存模式

###### 缓存预加载

###### 同步改为异步刷新

##### 服务自动扩容

* 如AWS的auto scaling

##### 服务调用者降级服务

###### 资源隔离

* 对调用服务的线程池进行隔离.

###### 对依赖服务进行分类

根据具体业务,将依赖服务分为：

* 强服务：强依赖服务不可用会导致当前业务中止
* 弱服务：弱依赖服务的不可用不会导致当前业务的中止.

###### 不可用服务的快速调用失败

* 一般通过 **超时机制**, **熔断器** 和熔断后的 **降级方法** 来实现.



#### Hystrix设计原则

Netflix的 **Hystrix** 是一个帮助解决分布式系统交互时超时处理和容错的类库, 它同样拥有保护系统的能力.

##### 资源隔离：运用在服务调用者

* 在一个高度服务化的系统中,我们实现的一个业务逻辑通常会依赖多个服务,比如: 商品详情展示服务会依赖商品服务, 价格服务, 商品评论服务.

  ![](https://segmentfault.com/img/bVzh9U)

* 调用三个依赖服务会共享商品详情服务的线程池. 如果其中的商品评论服务不可用, 就会出现线程池里所有线程都因等待响应而被阻塞, 从而造成服务雪崩.

* Hystrix通过将每个依赖服务分配独立的线程池进行资源隔离, 从而避免服务雪崩. 如下图所示, 当商品评论服务不可用时, 即使商品服务独立分配的20个线程全部处于同步等待状态,也不会影响其他依赖服务的调用.

  ![](https://segmentfault.com/img/bVziah)

##### 熔断器

* 定义了熔断器开关相互转换的逻辑：服务的健康状况 = 请求失败数 / 请求总数. 

* 熔断器开关由关闭到打开的状态转换是通过当前服务健康状况和设定阈值比较决定的.

  ![](https://segmentfault.com/img/bVziaa)

  * 当熔断器开关关闭时, 请求被允许通过熔断器. 如果当前健康状况高于设定阈值, 开关继续保持关闭. 如果当前健康状况低于设定阈值, 开关则切换为打开状态.
  * 当熔断器开关打开时, 请求被禁止通过.
  * 当熔断器开关处于打开状态, 经过一段时间后, 熔断器会自动进入半开状态, 这时熔断器只允许一个请求通过. 当该请求调用成功时, 熔断器恢复到关闭状态. 若该请求失败, 熔断器继续保持打开状态, 接下来的请求被禁止通过.

* 能保证服务调用者在调用异常服务时, 快速返回结果, 避免大量的同步等待. 并且熔断器能在一段时间后继续侦测请求执行结果, 提供恢复服务调用的可能.

##### 命令模式

* 使用命令模式(继承HystrixCommand类)来包裹具体的服务调用逻辑(run方法), 并在命令模式中添加了服务调用失败后的降级逻辑(getFallback).同时我们在Command的构造方法中可以定义当前服务线程池和熔断器的相关参数. 

  ```java
  public class Service1HystrixCommand extends HystrixCommand<Response> {
    private Service1 service;
    private Request request;
  
    public Service1HystrixCommand(Service1 service, Request request){
      supper(
        Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey("ServiceGroup"))
            .andCommandKey(HystrixCommandKey.Factory.asKey("servcie1query"))
            .andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey("service1ThreadPool"))
            .andThreadPoolPropertiesDefaults(HystrixThreadPoolProperties.Setter()
              .withCoreSize(20))//服务线程池数量
            .andCommandPropertiesDefaults(HystrixCommandProperties.Setter()
              .withCircuitBreakerErrorThresholdPercentage(60)//熔断器关闭到打开阈值
              .withCircuitBreakerSleepWindowInMilliseconds(3000)//熔断器打开到关闭的时间窗长度
        ))
        this.service = service;
        this.request = request;
      );
    }
  
    @Override
    protected Response run(){
      return service1.call(request);
    }
  
    @Override
    protected Response getFallback(){
      return Response.dummy();
    }
  }
  ```

* 在使用了Command模式构建了服务对象之后, 服务便拥有了熔断器和线程池的功能. 

  ![](https://segmentfault.com/img/bVzh96)

  

  

#### 内部处理逻辑

![](https://segmentfault.com/img/bVziap)

1. 构建Hystrix的Command对象, 调用执行方法.
2. Hystrix检查当前服务的熔断器开关是否开启, 若开启, 则执行降级服务getFallback方法.
3. 若熔断器开关关闭, 则Hystrix检查当前服务的线程池是否能接收新的请求, 若超过线程池已满, 则执行降级服务getFallback方法.
4. 若线程池接受请求, 则Hystrix开始执行服务调用具体逻辑run方法.
5. 若服务执行失败, 则执行降级服务getFallback方法, 并将执行结果上报Metrics更新服务健康状况.
6. 若服务执行超时, 则执行降级服务getFallback方法, 并将执行结果上报Metrics更新服务健康状况.
7. 若服务执行成功, 返回正常结果.
8. 若服务降级方法getFallback执行成功, 则返回降级结果.
9. 若服务降级方法getFallback执行失败, 则抛出异常.

### 缓存设计

#### 缓存穿透现象

##### 概述

指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。

##### 解决方案

* 布隆过滤器：将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力
* 缓存空数据：如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。

#### 缓存击穿现象

##### 概述

在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。

##### 解决方案

* 考虑用加锁或者队列的方式保证缓存的单线 程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。
* 分散缓存失效时间：在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。

#### 缓存击穿

##### 概述

* 对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。
* 和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。

##### 解决方案

###### 使用互斥锁(mutex key)

* 就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。
  * SETNX，是「SET if Not eXists」的缩写，也就是只有不存在的时候才设置，可以利用它来实现锁的效果
* 单机环境用并发包的Lock类型就行，集群环境则使用分布式锁( redis的setnx)

###### 异步构建缓存

* 构建缓存采取异步策略，会从线程池中取线程来异步构建缓存，从而不会让所有的请求直接怼到数据库上。该方案redis自己维护一个timeout，当timeout小于System.currentTimeMillis()时，则进行缓存更新，否则直接返回value值。

###### “永远不过期”

* 从redis上看，确实没有设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。
* 从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期

###### 热点数据：热点数据单独存储；使用本地缓存；分成多个子key；

## 跨机房容灾/异地多活

## 容灾演练

## 平滑启动

- 平滑重启应用思路 1.端流量（如vip层）、2. flush 数据(如果有)、3, 重启应用
- [《JVM安全退出（如何优雅的关闭java服务）》](https://blog.csdn.net/u011001084/article/details/73480432) 推荐推出方式：System.exit，Kill SIGTERM；不推荐 kill-9；用 Runtime.addShutdownHook 注册钩子。
- [《常见Java应用如何优雅关闭》](http://ju.outofmemory.cn/entry/337235) Java、Spring、Dubbo 优雅关闭方式。