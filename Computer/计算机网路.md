# 计算机网络

[TOC]



## OSI七层及TCP/IP五层网络协议

### 表格对比

| OSI七层网络模型         | TCP/IP四层概念模型      | 对应网络协议                            |
| ----------------------- | ----------------------- | --------------------------------------- |
| 应用层（Application）   | 应用层                  | HTTP、TFTP, FTP, NFS, WAIS、SMTP        |
| 表示层（Presentation）  |                         | Telnet, Rlogin, SNMP, Gopher            |
| 会话层（Session）       |                         | SMTP, DNS                               |
| 传输层（Transport）     | 传输层                  | TCP, UDP                                |
| 网络层（Network）       | 网络层                  | IP, ICMP, ARP, RARP, AKP, UUCP          |
| 数据链路层（Data Link） | 数据链路层（Data Link） | FDDI, Ethernet, Arpanet, PDN, SLIP, PPP |
| 物理层（Physical）      | 物理层（Physical）      | IEEE 802.1A, IEEE 802.2到IEEE 802.11    |

### 图

![](http://img.blog.csdn.net/20160731161720376)

### 数据传输过程

![](https://images2015.cnblogs.com/blog/849589/201706/849589-20170628002845914-1085185628.png)

![](https://camo.githubusercontent.com/797e891dc1fa83f905a18f60554c48b29b954817/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f352f382f313633336561643331366430373731333f773d38343126683d3131393326663d706e6726733d363039353133)

### 协议各层作用

#### 应用层

##### 简介

* **主要任务是通过应用进程间的交互来完成特定网络应用**
* **定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则**
  * **对于不同的网络应用需要不同的应用层协议。在互联网中应用层协议很多，如域名系统DNS**，支持万维网应用的 **HTTP协议**，支持电子邮件的 **SMTP协议**等等
  * 应用层交互的数据单元称为报文。

##### 常见协议

* 域名系统(DNS)
* HTTP

##### 设备：应用网关

#### 传输层

##### 简介

* **主要任务就是负责向两台主机进程之间的通信提供通用的数据传输服务**
  * 应用进程利用该服务传送应用层报文。
  * “通用的”是指并不针对某一个特定的网络应用，而是多种应用可以使用同一个运输层服务。
  * 由于一台主机可同时运行多个线程，因此运输层有复用和分用的功能。
    * 复用就是指多个应用层进程可同时使用下面运输层的服务
    * 分用和复用相反，是运输层把收到的信息分别交付上面应用层中的相应进程。

##### 常见协议

###### **传输控制协议 TCP**（Transmisson Control Protocol）--提供**面向连接**的，**可靠的**数据传输服务。

1. TCP 是面向连接的。（就好像打电话一样，通话前需要先拨号建立连接，通话结束后要挂机释放连接）；
2. 每一条 TCP 连接只能有两个端点，每一条TCP连接只能是点对点的（一对一）；
3. TCP 提供可靠交付的服务。通过TCP连接传送的数据，无差错、不丢失、不重复、并且按序到达；
4. TCP 提供全双工通信。TCP 允许通信双方的应用进程在任何时候都能发送数据。TCP 连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据；
5. 面向字节流。TCP 中的“流”（Stream）指的是流入进程或从进程流出的字节序列。“面向字节流”的含义是：虽然应用程序和 TCP 的交互是一次一个数据块（大小不等），但 TCP 把应用程序交下来的数据仅仅看成是一连串的无结构的字节流。

###### **用户数据协议 UDP**（User Datagram Protocol）--提供**无连接**的，尽最大努力的数据传输服务（**不保证数据传输的可靠性**）

1. UDP 是无连接的；
2. UDP 使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态（这里面有许多参数）；
3. UDP 是面向报文的；
4. UDP 没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如 直播，实时视频会议等）；
5. UDP 支持一对一、一对多、多对一和多对多的交互通信；
6. UDP 的首部开销小，只有8个字节，比TCP的20个字节的首部要短。

##### 设备：传输网关

#### 网络层

##### 简介

* **任务就是选择合适的网间路由和交换结点， 确保数据及时传送**
  * 因为**在 计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网**
*  在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP/IP 体系结构中，由于网络层使用 **IP 协议**，因此分组也叫 **IP 数据报** ，简称 **数据报**。
* 强调指出，网络层中的“网络”二字已经不是我们通常谈到的具体网络，而是指计算机网络体系结构模型中第三层的名称.
* 互联网是由大量的异构（heterogeneous）网络通过路由器（router）相互连接起来的。互联网使用的网络层协议是无连接的网际协议（Intert Prococol）和许多路由选择协议，因此互联网的网络层也叫做**网际层**或**IP层**。

##### 设备：路由器

#### 数据链路层

##### 简介

* **简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。**
*  在两个相邻节点之间传送数据时，**数据链路层将网络层交下来的 IP 数据报组装程帧**，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）。
* 在接收数据时，控制信息使接收端能够知道一个帧从哪个比特开始和到哪个比特结束。这样，数据链路层在收到一个帧后，就可从中提出数据部分，上交给网络层。 
  * 控制信息还使接收端能够检测到所收到的帧中有误差错。如果发现差错，数据链路层就简单地丢弃这个出了差错的帧，以避免继续在网络中传送下去白白浪费网络资源。
  * 如果需要改正数据在链路层传输时出现差错（这就是说，数据链路层不仅要检错，而且还要纠错），那么就要采用可靠性传输协议来纠正出现的差错。这种方法会使链路层的协议复杂些。

##### 设备：网桥、交换机

#### 物理层

##### 简介

* **作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。**使其上面的数据链路层不必考虑网络的具体传输介质是什么
  * “透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。
* 所传送的数据单位是比特

##### 设备：中继器、集线器





## TCP、UDP协议

### TCP三次握手

![](https://user-gold-cdn.xitu.io/2018/12/28/167f252e34271519?imageView2/0/w/1280/h/960/ignore-error/1)

#### 过程

##### 第一次握手

客户端向服务端发送1个连接请求**SYN标志**的报文段，客户端进入**SYN_SENT**(同步已发送)状态

* 同步标识位设为SYN(Synchronize)设为1：SYN = 1
  * SYN 是 TCP/IP 建立连接时使用的握手信号
* 随机携带一个起始序号seq(Sequence)，seq = x
* 不携带数据(因SYN位被设置为1的报文段不能携带数据，但要消耗一个序号)

##### 第二次握手

服务端收到请求连接报文段后，若同意建立连接，则向客户端发回连接确认(**SYN+ACK**)的报文段，并为该TCP连接分配TCP缓存及变量。服务端进入**SYN_REVD**(同步已接收)状态

* 同步标识位设为SYN(Synchronize)设为1：SYN = 1
* 确认标识位设为ACK(Acknowledge)设为1：ACK = 1
* 随机携带一个起始序号seq(Sequence)，seq = y
* 确认号字段 ack(Acknowledgement Number)，ack = x + 1
  * x + 1对上一个报文段进行确认，客户端在第三次握手即可知道该请求是对第一次握手的正确回应
* 不携带数据(原因同上)

##### 第三次握手

客户端收到确认报文段后，向服务器再次发出连接确认(**SYN+ACK**)报文段，并为该TCP连接分配TCP缓存及变量。客户端、服务端都进入ESTABLISHED(已创建)状态。

* 确认标识位设为ACK(Acknowledge)设为1：ACK = 1
* 序号，seq = x + 1
* 确认号字段 ack(Acknowledgement Number)，ack = y + 1
* 可携带数据(SYN不设为1，若不携带数据则不消耗序号)

#### 其他

* 因 `TCP`提供的是全双工通信，故通信双方的应用进程在任何时候都能发送数据
* 三次握手期间，任何1次未收到对面的回复，则都会重发

#### 为什么需要三次握手

* 解释1: **三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。**
  * 第一次握手：Client 什么都不能确认；Server 确认了对方发送正常
  * 第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己接收正常，对方发送正常
  * 第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送接收正常
* 解释2:  防止服务器端因接收了**早已失效的连接请求报文**，从而一直等待客户端请求，最终导致**形成死锁、浪费资源**
  * 假如不适用三次握手，客户端发出的第1个连接请求因网络问题延迟，在客户端重发请求2后服务端回应建立连接后，第1个连接请求才到达，服务端又新建了一条连接。这时候双方有两条连接，但只在请求2的连接上传输数据，请求1的连接对客户端来说已失效因此不知道有这连接，而服务端又一直在等请求1连接的数据。

### TCP四次挥手

#### 过程

![](https://user-gold-cdn.xitu.io/2018/12/28/167f252e605d3801?imageView2/0/w/1280/h/960/ignore-error/1)

##### 第一次挥手

客户端向服务端发送1个连接释放**FIN标志**的报文段，客户端进入**FIN_WAIT_1**(终止等待1)状态，停止再发送数据等待服务器的确认

- 终止控制位设为FIN(Finish)设为1：FIN = 1
  - FIN 是 TCP/IP 释放连接时使用的挥手信号
- 报文段序号seq(Sequence)设为前面传输数据最后一个字节的序号加1，seq = u
- 可携带数据(FIN=1的报文即使不携带数据也消耗1个序号)

##### 第二次挥手

服务端收到连接释放报文段后，则向客户端发回同意连接释放的报文段。服务端进入**CLOSE_WAIT**(关闭等待)状态；客户端收到服务端确认号，进入**FIN_WAIT_2**(终止等待2)状态，等待服务器发出是否连接请求。**至此，客户端->服务端的TCP连接已断开，即TCP连接处于半关闭状态，但服务端->客户端的TCP连接未断开**

- 确认标识位设为ACK(Acknowledge)设为1：ACK = 1
- 报文段序号seq(Sequence)设为前面传输数据最后一个字节的序号加1，seq = v
- 确认号字段 ack(Acknowledgement Number)，ack = u + 1

##### 第三次挥手

若服务器已无要向客户端发送数据，则发出释放连接的报文段，服务端进入**LAST_ACK**（最后确认）状态

* 终止控制位设为FIN(Finish)设为1：FIN = 1

- 确认标识位设为ACK(Acknowledge)设为1：ACK = 1
- 报文段序号，seq = w
- 重复上次已发送的确认号字段 ack(Acknowledgement Number)，ack = u + 1
  - 表明二次和三次挥手间没有其他数据传输
- 可携带数据(FIN=1的报文即使不携带数据也消耗1个序号)

##### 第四次挥手

客户端收到连接释放报文段后，则向服务器发回连接释放确认报文段。客户端进入TIME_WAIT(时间等待)状态，服务端进入CLOSED(关闭)状态。**此时TCP连接还未释放，须经过连接等待计时器设置的时间2MSL后，客户端才进入CLOSED(连接关闭)状态，即服务端进入关闭状态比客户端更早**

- 确认标识位设为ACK(Acknowledge)设为1：ACK = 1
- 报文段序号，seq = u + 1
- 确认号字段 ack(Acknowledgement Number)，ack = w + 1
  - 表明二次和三次挥手间没有其他数据传输
- 可携带数据(FIN=1的报文即使不携带数据也消耗1个序号)

#### 为什么需要四次挥手

* 解释1: 任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。
  * 举个例子：A 和 B 打电话，通话即将结束后，A 说“我没啥要说的了”，B回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话，于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”，A 回答“知道了”，这样通话才算结束。
* 解释2: 为了保证通信双方**分别**都能通知对方 需释放 & 断开连接
  * 释放连接是单向操作，1请求1答复*1客户端1服务端=4次挥手

#### 为什么客户端关闭要等待2MSL(最长报文段寿命（`Maximum Segment Lifetime`）)时间/TIME_WAIT的作用是什么？

* 原因1: 为了保证客户端发送的最后1个连接释放确认报文 能到达服务器，从而使得服务器能正常释放连接
  * 假设客户端不等待直接关闭，客户端发送的确认释放连接请求丢失，服务端会重发第三次挥手但客户端无法接收，因此服务端无法进入关闭状态。2MSL=第四次挥手时间+服务端重发第三次挥手时间
* 原因2: 防止 上文提到的早已失效的连接请求报文 出现在本连接中 客户端发送了最后1个连接释放请求确认报文后，再经过2`MSL`时间，则可使本连接持续时间内所产生的所有报文段都从网络中消失



### TCP、UDP区别

##### TCP

###### 面向连接

* 在传送数据之前必须先建立连接，数据传送结束后要释放连接

###### 不提供广播或多播服务

###### 提供可靠的，面向连接的运输服务

* TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源
* 增加了许多开销，如确认，流量控制，计时器以及连接管理等
* 协议数据单元的首部增大很多，还要占用许多处理机资源

###### 一般用于文件传输、发送和接收邮件、远程登录等场景。

##### UDP

###### 不需要先建立连接

* 远地主机在收到 UDP 报文后，不需要给出任何确认

######  不提供可靠交付，某些场景下是最有效工作方式（一般用于即时通信）

* 比如： QQ 语音、 QQ 视频 、直播等等



### TCP如何保证可靠传输

#### 切割应用数据

* 应用数据被分割成 TCP 认为最适合发送的数据块

#### 将数据包编号进行有序传输

* TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。

#### **校验和**

*  TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。

#### 接收端会丢弃重复的数据

#### **流量控制**

##### 概述

* TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）
* 接收方根据自己接受不了缓存的大小，动态调整发送方的发送窗口大小，从而控制发送方的发送速率

##### 滑动窗口

- TCP 利用滑动窗口实现流量控制的机制。
- 滑动窗口（Sliding window）是一种流量控制技术。早期的网络通信中，通信双方不会考虑网络的拥挤情况直接发送数据。由于大家不知道网络拥塞状况，同时发送数据，导致中间节点阻塞掉包，谁也发不了数据，所以就有了滑动窗口机制来解决此问题。
- TCP 中采用滑动窗口来进行传输控制，滑动窗口的大小意味着接收方还有多大的缓冲区可以用于接收数据。发送方可以通过滑动窗口的大小来确定应该发送多少字节的数据。当滑动窗口为 0 时，发送方一般不能再发送数据报，但有两种情况除外，一种情况是可以发送紧急数据，例如，允许用户终止在远端机上的运行进程。另一种情况是发送方可以发送一个 1 字节的数据报来通知接收方重新声明它希望接收的下一字节及发送方的滑动窗口大小。

#### **拥塞控制**

##### 概述

* 在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。当网络拥塞时，减少数据的发送
* 防止过多的数据注入到网络中，使得网络中的路由器 & 链路不致于过载
* 拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。
* 拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素

##### 与流量控制区别

| 类型     | 范围           | 面向对象                        | 实际措施             |
| -------- | -------------- | ------------------------------- | -------------------- |
| 拥塞控制 | 全局性         | 整个通信网络(含所有主机&路由器) | 防止过多数据注入网络 |
| 流量控制 | 点对点、端到端 | 发送端                          | 降低发送端的速率     |

##### 解决方案

###### 拥塞窗口

* 发送方维持一个窗口变量(cwnd, congestion window)，反映当前容量&拥塞情况
* 窗口大小取决于网络拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。
* 发送方控制拥塞窗口原则
  * 网络无拥塞时，增大拥塞窗口，以便把更多分组发送出去
  * 网络拥塞时，减小拥塞窗口，以减小注入到网络中的分组数

###### 慢开始算法

慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，**较好的方法是先探测一下，即由小到大逐渐增大发送窗口**，也就是由小到大逐渐增大拥塞窗口数值。**cwnd初始值为1，每经过一个传播轮次，cwnd加倍。**

###### 拥塞避免算法

拥塞避免算法的思路是让拥塞窗口cwnd缓慢增大，即每经过一个往返时间RTT就把发送放的cwnd加1.

* **拥塞避免 并不可避免拥塞**，只是将拥塞窗口按现行规律缓慢增长，使得网络比较不容易出现拥塞
* 相比慢开始算法的加倍，拥塞窗口增长速率缓慢得多

###### 快重传算法

- 原理
  1. 接收方 每收到一个失序的报文段后 就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方），而不要等到自己发送数据时才进行捎带确认
  2. 发送方只要一连收到3个重复确认就立即重传对方尚未收到的报文段，而不必 继续等待设置的重传计时器到期
- 作用 由于发送方尽早重传未被确认的报文段，因此采用快重传后可以使整个网络吞吐量提高约20%

###### 快恢复算法

当发送方连续收到3个重复确认后，就：

1. 执行 **乘法减小** 算法：把 慢开始门限`（ssthresh）`设置为 出现拥塞时发送方窗口值的一半 = 拥塞窗口的1半
2. 将拥塞窗口`（cwnd）`值设置为 慢开始门限`ssthresh`减半后的数值 = 拥塞窗口的1半
3. 执行 **加法增大** 算法：执行拥塞避免算法，使拥塞窗口缓慢地线性增大。

###### 拥塞控制规则

![](https://user-gold-cdn.xitu.io/2018/12/28/167f252f4a3464e3?imageView2/0/w/1280/h/960/ignore-error/1)

#### **停止等待协议**

##### 概述

* 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组
* 在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认

##### 场景

###### 无差错情况

发送方发送分组,接收方在规定时间内收到,并且回复确认.发送方再次发送。

![](https://camo.githubusercontent.com/87a4e3d99e9e650c22572eb8ba3ccf74feb86d30/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f382f31362f313635343166613863333831366139303f773d35313426683d34373326663d706e6726733d39393234)

###### **出现差错情况（超时重传)，客户端请求异常**

* 停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。

  * 因此每发送完一个分组需要设置一个超时计时器，其重转时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为 **自动重传请求 ARQ** 。

    1. 自动重传请求 ARQ 协议
       * 停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重转时间应比数据在分组传输的平均往返时间更长一些。
       * **优点：** 简单
       * **缺点：** 信道利用率低

    2. **连续 ARQ 协议** 
       * 可提高信道利用率。发送维持一个发送窗口，凡位于发送窗口内的分组可连续发送出去，而不需要等待对方确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了。
       * **优点：** 信道利用率高，容易实现，即使确认丢失，也不必重传。
       * **缺点：** 不能向发送方反映出接收方已经正确收到的所有分组的信息。 比如：发送方发送了 5条 消息，中间第三条丢失（3号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息。

  * 另外在停止等待协议中若收到重复分组，就丢弃该分组，但同时还要发送确认。

  ![](https://camo.githubusercontent.com/b499ea2d7d33b0d69af03f8dbdec2321f811d1a0/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f382f31362f313635343166616566646632343961623f773d39353326683d34383026663d706e6726733d3139313633)

###### **确认丢失**：确认消息在传输过程丢失 ，服务端请求异常

当A发送M1消息，B收到后，B向A发送了一个M1确认消息，但却在传输过程中丢失。而A并不知道，在超时计时过后，A重传M1消息，B再次收到该消息后采取以下两点措施：

1. 丢弃这个重复的M1消息，不向上层交付。
2. 向A发送确认消息。（不会认为已经发送过了，就不再发送。A能重传，就证明B的确认消息丢失）

![](https://camo.githubusercontent.com/860937399b9aee59e78044f0c323cb0e24d6f5b7/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f382f31362f313635343166623639343161373136353f773d39313826683d34363126663d706e6726733d3139383431)

###### **确认迟到** ：确认消息在传输过程中迟到，服务端请求异常

A发送M1消息，B收到并发送确认。在超时时间内没有收到确认消息，A重传M1消息，B仍然收到并继续发送确认消息（B收到了2份M1）。此时A收到了B第二次发送的确认消息。接着发送其他数据。过了一会，A收到了B第一次发送的对M1的确认消息（A也收到了2份确认消息）。处理如下：

1. A收到重复的确认后，直接丢弃。
2. B收到重复的M1后，也直接丢弃重复的M1。

![](https://camo.githubusercontent.com/26a9448d6b1d283bb0490a0c50630f88fde885fa/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f382f31362f313635343166646438353932396536623f773d38393926683d34353026663d706e6726733d3233313635)

#### **超时重传**

当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。





## HTTP1.0&HTTP1.1&HTTP2.0

### HTTP1.0

#### 无状态

* `HTTP1.0`规定浏览器和服务器保持短暂的连接，浏览器的每次请求都需要与服务器建立一个`TCP`连接，服务器处理完成后立即断开`TCP`连接（无连接）
* 缺陷
  * 最大的性能缺陷就是**无法复用连接**
    * 每次发送请求的时候，都需要进行一次`TCP`的连接，而`TCP`的连接释放过程又是比较费事的。这种无连接的特性会使得网络的利用率非常低。
  * 队头阻塞（`head of line blocking`）。由于`HTTP1.0`规定下一个请求必须在前一个请求响应到达之前才能发送。假设前一个请求响应一直不到达，那么下一个请求就不发送，同样的后面的请求也给阻塞了。

#### 无连接

* 服务器不跟踪每个客户端也不记录过去的请求（无状态）
  * 这种无状态性可以借助`cookie/session`机制来做身份认证和状态记录

### HTTP1.1

继承了`HTTP1.0`简单的特点，还克服了诸多`HTTP1.0`性能上的问题

#### 长连接

* `HTTP1.1`增加了一个`Connection`字段，通过设置`Keep-Alive`可以保持`HTTP`连接不断开，避免了每次客户端与服务器请求都要重复建立释放建立`TCP`连接，提高了网络的利用率。
  * 如果客户端想关闭`HTTP`连接，可以在请求头中携带`Connection: false`来告知服务器关闭请求。
* 在HTTP1.1中默认开启Connection： keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。

#### 管道化（`pipelining`）

* 基于`HTTP1.1`的长连接，使得请求管线化成为可能。管线化使得请求能够“并行”传输。
  * 举个例子来说，假如响应的主体是一个`html`页面，页面中包含了很多`img`，这个时候`keep-alive`就起了很大的作用，能够进行“并行”发送多个请求。
  * **服务器必须按照客户端请求的先后顺序依次回送相应的结果，以保证客户端能够区分出每次请求的响应内容。**也就是说，`HTTP`管道化可以让我们把先进先出队列从客户端（请求队列）迁移到服务端（响应队列）。
    * 客户端同时发了两个请求分别来获取`html`和`css`，假如说服务器的`css`资源先准备就绪，服务器也会先发送`html`再发送`css`。换句话来说，只有等到`html`响应的资源完全传输完毕后，`css`响应的资源才能开始传输。
  * 不允许同时存在两个**并行的响应**。
  * 还是无法解决队头阻塞（`head of line blocking`）的问题。同时“管道化”技术存在各种各样的问题，所以很多浏览器要么根本不支持它，要么就直接默认关闭，并且开启的条件很苛刻...而且实际上好像并没有什么用处。
* 虽然`HTTP1.1`支持管道化，但是服务器也必须进行逐个响应的送回，这个是很大的一个缺陷。实际上，现阶段的浏览器厂商采取了另外一种做法，它允许我们打开多个TCP的会话。浏览器看到的并行请求，，其实是不同的TCP连接上的`HTTP`请求和响应。这也就是我们所熟悉的浏览器对同域下并行加载6~8个资源的限制。而这，才是真正的**并行**！

#### **缓存处理**

* 在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。

#### **带宽优化及网络连接的使用**

HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。

#### **错误通知的管理**

在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。

#### **Host头处理**

在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。



### HTTP2.0

> 是不是启用HTTP 2.0后性能必然提升了？任何事情都不是绝对的，虽然总体而言性能肯定是能提升的。 
>
> 我想HTTP 2.0会带来新的性能瓶颈。因为现在所有的压力集中在底层一个TCP连接之上，TCP很可能就是下一个性能瓶颈，比如TCP分组的队首阻塞问题，单个TCP packet丢失导致整个连接阻塞，无法逃避，此时所有消息都会受到影响。未来，服务器端针对HTTP 2.0下的TCP配置优化至关重要

#### 二进制分帧

* **HTTP 2.0性能增强的核心**。将所有的传输信息分割为更小的消息和帧，并对它们采用二进制格式编码。
* 客户端和服务端都需要引入新的二进制编码和解码的机制。
* HTTP 2.0并没有改变HTTP 1.x的语义，只是在应用层使用二进制分帧方式传输。 
  * 把原来`HTTP1.x`的`header`和`body`部分用`frame`重新封装了一层而已。
* ![](https://segmentfault.com/img/remote/1460000013028804?w=625&h=324)

#### **多路复用（连接共享）**

##### 术语

- 流（`stream`）：已建立连接上的双向字节流。
- 消息：与逻辑消息对应的完整的一系列数据帧。
- 帧（`frame`）：`HTTP2.0`通信的最小单位，每个帧包含帧头部，至少也会标识出当前帧所属的流（`stream id`）。

##### 概述

![](https://segmentfault.com/img/remote/1460000013028805?w=479&h=391)

* 从图中可见，所有的`HTTP2.0`通信都在一个`TCP`连接上完成，这个连接可以承载任意数量的双向数据流。
* 每个数据流以消息的形式发送，而消息由一或多个帧组成。**这些帧可以乱序发送，然后再根据每个帧头部的流标识符（`stream id`）重新组装。**
  * 举个例子，每个请求是一个数据流，数据流以消息的方式发送，而消息又分为多个帧，帧头部记录着`stream id`用来标识所属的数据流，不同属的帧可以在连接中随机混杂在一起。接收方可以根据`stream id`将帧再归属到各自不同的请求当中去。
* 多路复用（连接共享）可能会导致关键请求被阻塞。**`HTTP2.0`里每个数据流都可以设置优先级和依赖，优先级高的数据流会被服务器优先处理和返回给客户端，数据流还可以依赖其他的子数据流。**
  * 不能过分迷信请求优先级，仍然要注意以下问题：
    - 服务端是否支持请求优先级
    - 会否引起队首阻塞问题，比如高优先级的慢响应请求会阻塞其他资源的交互。
* **`HTTP2.0`实现了真正的并行传输，它能够在一个`TCP`上进行任意数量`HTTP`请求。而这个强大的功能则是基于“二进制分帧”的特性。**

#### 头部压缩

* 在`HTTP1.x`中，头部元数据都是以纯文本的形式发送的，通常会给每个请求增加500~800字节的负荷。
  * 比如说`cookie`，默认情况下，浏览器会在每次请求的时候，把`cookie`附在`header`上面发送给服务器
* `HTTP2.0`使用`encoder`来减少需要传输的`header`大小，通讯双方各自`cache`一份`header fields`表，既避免了重复`header`的传输，又减小了需要传输的大小。
  * 高效的压缩算法可以很大的压缩`header`，减少发送包的数量从而降低延迟。

#### 服务端推送

服务器除了对最初请求的响应外，服务器还可以额外的向客户端推送资源，而无需客户端明确的请求。



## HTTPS

### 参考文章

[《https原理通俗了解》](https://www.cnblogs.com/zhangshitong/p/6478721.html)

### 过程

> HTTPS要使客户端与服务器端的通信过程得到安全保证，必须使用的对称加密算法，但是协商对称加密算法的过程，需要使用非对称加密算法来保证安全，然而直接使用非对称加密的过程本身也不安全，会有中间人篡改公钥的可能性，所以客户端与服务器不直接使用公钥，而是使用数字证书签发机构颁发的证书来保证非对称加密过程本身的安全。这样通过这些机制协商出一个
>
> 对称加密算法，就此双方使用该算法进行加密解密。从而解决了客户端与服务器端之间的通信安全问题。

* 使用非对称加密算法协商对称加密算法
* 用对称加密方式传输数据
* 使用第三方机构签发的证书，来加密公钥，用于公钥的安全传输、防止被中间人串改
* ![](https://camo.githubusercontent.com/e28a26b73b7e71996534e7f20d82cd27831a818f/68747470733a2f2f6c6572616e32646565706c6561726e6a617661776562746563682e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f736f6d6570686f746f2f746c732545362542352538312545372541382538422e706e67)

