# 缓存

[TOC]



## 缓存失效策略

当缓存需要被清理时（比如空间占用已经接近临界值了），需要使用某种淘汰算法来决定清理掉哪些数据。常用的淘汰算法有下面几种：

### FIFO：First In First Out，先进先出。

判断被存储的时间，离目前最远的数据优先被淘汰。

### LRU：Least Recently Used，最近最少使用。

判断最近被使用的时间，目前最远的数据优先被淘汰。

### LFU：Least Frequently Used，最不经常使用。

在一段时间内，数据被使用次数最少的，优先被淘汰。

## 一致性哈希

### 解决的问题

在传统的哈希算法下，每条缓存数据落在那个节点是通过哈希算法和服务器节点数量计算出来的，一旦服务器节点数量发生增加或者介绍，哈希值需要重新计算，此时几乎所有的数据和服务器节点的对应关系也会随之发生变化，进而会造成绝大多数缓存的失效

### 简介

一致性哈希算法通过环形结构和虚拟节点的概念，确保了在缓存服务器节点数量发生变化时大部分数据保持原地不动，从而大幅提高了缓存的有效性

### 原理

* 首先将哈希空间映射到一个虚拟的环上，环上的数值分从 0 到 2^32-1（哈希值的范围）

* 使用同样的哈希算法将缓存服务节点（通常通过服务器IP+端口作为节点的key）和数据键映射到环上的位置。

* 决定数据落在那台服务器上时，使用一致的方向（比如顺时针方向）沿环查找，遇到的第一个有效服务器就是缓存保存的地方

* 当有新的服务器节点加入时，按照同样的哈希算法将新节点映射到环上的某处位置，和新节点相邻的数据逆时针节点会进行迁移，其他节点保持不变。

  * 如下图，当新加入一台新服务器 192.168.56.104 时，user_nick_pandy 这条缓存数据的请求根据算法会落在192.168.56.104 这台及其上，其他节点不受任何影响。

  ![](https://coderxing.gitbooks.io/architecture-evolution/assets/A026DF6E-060A-4295-83CB-FC4A7D229A03.png)

* 另外，由于哈希计算的记过通常都比较随机，如果缓存服务器比较少的话，可能会出现数据分配冷热不均的问题。为了解决这个问题，我们引入虚拟节点的概念，在实体服务器不增加的情况下，用多个虚拟节点替代原来的单个实体节点，一台服务服务器在环上就对应多个位置，这样可以让数据存储更加均匀，各服务器的负载页更加平衡

  ![](https://coderxing.gitbooks.io/architecture-evolution/assets/9B7CB81A-434E-4C33-B65E-3821C19E3B70.png)

## 客户端缓存

### 协议缓存/浏览器缓存/网页缓存

#### 概述

http协议缓存机制是指通过 HTTP 协议头里的 Cache-Control（或 Expires）和 Last-Modified（或 Etag）等字段来控制文件缓存的机制。

* **Cache-Control** 用于控制文件在本地缓存有效时长。最常见的，比如服务器回包：Cache-Control:max-age=600 表示文件在本地应该缓存，且有效时长是600秒（从发出请求算起）。在接下来600秒内，如果有请求这个资源，浏览器不会发出 HTTP 请求，而是直接使用本地缓存的文件。
  * Cache-Control 还有一个同功能的字段：Expires。Expires 的值一个绝对的时间点，如：Expires: Thu, 10 Nov 2015 08:45:11 GMT，表示在这个时间点之前，缓存都是有效的。
  * Expires 是 HTTP1.0 标准中的字段，Cache-Control 是 HTTP1.1 标准中新加的字段，功能一样，都是控制缓存的有效时间。当这两个字段同时出现时，Cache-Control 是高优化级的。
* **Last-Modified** 是标识文件在服务器上的最新更新时间。下次请求时，如果文件缓存过期，浏览器通过 If-Modified-Since 字段带上这个时间，发送给服务器，由服务器比较时间戳来判断文件是否有修改。如果没有修改，服务器返回304告诉浏览器继续使用缓存；如果有修改，则返回200，同时返回最新的文件。
* **Etag** 也是和 Last-Modified 一样，对文件进行标识的字段。不同的是，Etag 的取值是一个对文件进行标识的特征字串。在向服务器查询文件是否有更新时，浏览器通过 If-None-Match 字段把特征字串发送给服务器，由服务器和文件最新特征字串进行匹配，来判断文件是否有更新。没有更新回包304，有更新回包200。
  * Etag 和 Last-Modified 可根据需求使用一个或两个同时使用。两个同时使用时，只要满足基中一个条件，就认为文件没有更新。

#### 两种刷新缓存的特殊情况

1. **手动刷新页面**（F5)，浏览器会直接认为缓存已经过期（可能缓存还没有过期），在请求中加上字段：Cache-Control:max-age=0，发包向服务器查询是否有文件是否有更新。
2. **强制刷新页面**（Ctrl+F5)，浏览器会直接忽略本地的缓存（有缓存也会认为本地没有缓存），在请求中加上字段：Cache-Control:no-cache（或 Pragma:no-cache），发包向服务重新拉取文件。

### HTML5应用缓存

HTML5 提供一种应用程序缓存机制，使得基于web的应用程序可以离线运行。为了能够让用户在离线状态下继续访问 Web 应用，开发者需要提供一个 cache manifest 文件。这个文件中列出了所有需要在离线状态下使用的资源，浏览器会把这些资源缓存到本地。

### HTML5本地存储

DOM Storage、webSQL和indexedDB等

## 应用层本地缓存

### HashMap、ConcurrentHashMap，最简单

### EhCache，本地缓存框架支持多层缓存模型

#### 堆内缓存(on-heap)

* 使用JVM 中的堆空间来保存缓存对象，是最常见的缓存模式，好处是可以直接存储Java对象数据结构，而不需要强制序列化。
* 缺点是会挤占JVM内存空间，会引发GC（垃圾回收）的频次和时间会变长。

#### 堆外缓存(off-heap)

*  相比于堆内缓存，堆外缓存使用JVM对以外的内存空间，也就意味着可以使用更大的内存空间，空间大小只受限于本机内地大小，而且不受GC管理(内存对象转移，释放等等。。)，整体上可以减少GC带来的停顿影响
* 缺点是，堆外内存中的对象必须要序列化，键和值必须实现Serializable接口，因此存取速度上会比堆内缓存慢

#### 磁盘缓存(Disk)

* 可以持久化存储数据可以不丢失，也意味着可以使用更大的存储空间，缓存在磁盘上的数据也需要支持序列化，速度会被比内存更慢
* 使用时推荐使用更快的磁盘带来更大的吞吐率 

### Guava Cache，线程安全的全内存方式本地缓存

* 和 ConcurrentMap 相比，Guava Cache 可以限制内存的占用，并可设置缓存的过期时间，可以自动回收数据

## 服务端本地缓存

### Nginx本地缓存

*  Nginx 作为Web服务器或者负载均衡器，一般不执行业务逻辑，而是将请求转到后端服务器，比如 Tomcat 或者 php-fpm，后端处理完毕之后将经过 nginx 将数据返回给用户。在请求转发的过程中，nginx 可将中间数据在本地进行缓存，这样未来一段时间内的请求相同的数据，Nginx 可以直接返回本地复本，而不是再次向后端服务发起请求，可以大大降低后端服务器的压力。同时，在后端服务器宕机时，Nginx 还可返回缓存数据，而不中端服务，提高了服务的可用性。
*  Nginx 可以将缓存数据持久化到本地磁盘上， 重启之后会自动扫描磁盘的上缓存数据并建立索引，保证服务的持续性。

### PageSeed，改写前端源码及配置加速网站

### Varnish Cache, the high-performance HTTP accelerator.

### nuster，基于HAProxy的高性能HTTP缓存服务器和RESTful NoSQL缓存服务器。

### Squid ， Web Proxy Cache 

## 服务端缓存(缓存中间件)

### Memcached

#### 简介

* 自由开源的，高性能，分布式内存对象缓存系统，可提高Web应用扩展性
* 基于内存的key-value存储，用来存储小块的任意数据（字符串、对象）。这些数据可以是数据库调用、API调用或者是页面渲染的结果。
* 一般的使用目的是，通过缓存数据库查询结果，减少数据库访问次数，以提高动态Web应用的速度、提高可扩展性。
* 由C语言来实现的，全部代码仅有2000多行，采用的是异步I/O，其实现方式是基于事件的单进程和单线程的。使用libevent作为事件通知机制
* 多个服务器端可以协同工作，但这些服务器端之间是没有任何通信联系的
* 需要被缓存的数据以Key/Value键值对的形式保存在服务器端预分配的内存空间中
* 没有对缓存的数据进行持久性存储的设计，且当内存中缓存的数据容量达到启动时设定的内存值时，就自动使用LRU（最近最少使用算法）算法删除过期的缓存数据。
* 没有过多考虑数据的永久性问题。因此如果使用memcached作为缓存数据服务，要考虑数据丢失后带来的问题，例如：是否可以重新生成数据，还有，在高并发场合数据丢失会不会导致网站架构雪崩。

#### 特征

- 协议简单
  - 基于文本行的协议，能通过telnet直接操作memcached服务存取数据；
- 基于libevent的事件处理
  - libevent是个程序库，它将Linux的epoll、BSD类操作系统的kqueue等事件处理功能 封装成统一的接口。即使对[服务器](https://www.baidu.com/s?wd=%E6%9C%8D%E5%8A%A1%E5%99%A8&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd)的连接数增加，也能发挥O(1)的性能。
  - memcached使用这个libevent库，因此能在Linux、BSD、Solaris等操作系统上发挥其高性能
  - 参考
    - libevent: <http://www.monkey.org/~provos/libevent/>
    - The C10K Problem: <http://www.kegel.com/c10k.html>
- 内置内存存储方式
  - memcached有一套自己管理内存的方式，这套管理方式非常高效，所有的数据都保存在memcached内置的内存中，当存入的数据占满内存空间时，memcached就使用LRU算法自动删除不使用的缓存，即重用过期数据的内存空间
  - 为缓存系统设计的，因此，没有考虑数据的容灾问题，和机器的内存一样，重启机器后数据将会丢失
- memcached不互相通信的分布式
  - 各个memcached服务器之间互相不通信，都是独立的存取数据，不共享任何信息。
  - **通过对客户端的设计，让Memcached具有分布式功能，能支持海量缓存和大规模应用。**

#### 内存管理机制

##### 利用Slab Allocation机制来分配和管理内存(分割成固定内存块)

* 传统的内存管理方式是：使用完通过malloc分配的内存后通过free来回收内存。这种方式容易产生内存碎片并降低操作系统对内存的管理效率
* Slab Allocation机制不存在这样的问题。它按照预先分配的大小，将分配的内存分割成特定长度的内存块，再把尺寸相同的内存块分成组，这些内存块不会释放，可以重复利用。
  * 首先会将内存按照页（page，默认1M）来分割，并将页按需分配给 Slab 类，分配之后就不会再移动，然后在把slab按照块（chunk）的大小切割再次进行切割，其中 Slab 可以理解为块集合
  * Chunk是用于缓存记录的内存空间，Chunk 的大小默认按照1.25倍的速度递增。好处是不会频繁申请内存，提高IO效率，坏处是会有一定的内存浪费。
  * ![](https://coderxing.gitbooks.io/architecture-evolution/assets/23B603A9-D3D6-4536-A4A0-E48F613028C4.png)

##### 使用能存下数据的最小内存块

* 保存着一个空闲的内存块列表，当有数据存入时根据接收到的数据大小，分配一个能存下这个数据的最小内存块。
* 这种方式有时会造成内存浪费，例如：将200字节的一个数据存入300字节的一个内存块中，就会有100字节的内存被浪费掉，不能被使用。

##### 避免浪费内存的办法

* 预先计算出应用存入的数据大小，或把同一业务类型的数据存入一个Memcached服务器中，确保存入的数据大小相对均匀，这样就可以减少内存的浪费。
* 在memcached服务启动时，通过“ -f ” 选项指定一个增长因子（或叫增长系数），它能控制内存组（slab）之间的大小差异。在应用中使用Memcached时，通常可以不重新设置这个参数，使用默认值1.25进行部署。如果想优化memcached对内存的使用，可以考虑重新计算数据的预期平均长度，调整这个参数来获得合适的设置值。

#### 删除机制

* 不会释放已分配的内存空间，在数据过期后，客户端不能通过Key取出它的值，其存储空间被重新利用。
* 使用的是一种Lazy Expiration 策略，自己不会监控存入的“Key/Value”对是否过期，而是在获取Key值时查看记录的时间戳，检查“key/value”键值对的空间是否过期。这种策略不会在过期检测上浪费CPU资源。
* 分配空间时，优先使用已经过期的Key/Value键值对空间，当分配的内存空间占满时，Memcached就会使用LRU（最近最少使用算法）算法来分配空间，删除最近最少使用的Key/Value键值对，将其空间分配给新Key/Value键值对

### Redis

详见redis.md